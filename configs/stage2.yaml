# Stage-2: 自建数据微调（对齐+分类）训练配置
model:
  name: "google/siglip-base-patch16-224"
  resume_from: "outputs/stage1"
  load_in_4bit: true
  lora_r: 16
  lora_alpha: 16
  freeze_ratio: 0.6

data:
  train_images: "data/custom_app/images"
  train_captions: "data/custom_app/captions.jsonl"
  train_labels: "data/custom_app/labels.jsonl"
  label_map: "data/custom_app/label_map.json"
  image_size: 224
  max_text_length: 64
  train_split: 0.8
  val_split: 0.1
  test_split: 0.1

training:
  precision: "bf16"
  per_device_batch_size: 16
  gradient_accumulation_steps: 16
  learning_rate: 1e-5
  head_learning_rate: 1e-3
  weight_decay: 0.05
  epochs: 8
  warmup_ratio: 0.03
  scheduler: "cosine"
  lambda_align: 0.5
  early_stopping_patience: 3
  seed: 42

output:
  dir: "outputs/stage2"
  save_steps: 200
  eval_steps: 200
  logging_steps: 20